if(!require("mlbench")) install.packages("mlbench"); library("mlbench")
if(!require("caret")) install.packages("caret"); library("caret")
if(!require("data.table")) install.packages("data.table"); library("data.table")
if(!require("dplyr")) install.packages("dplyr"); library("dplyr")
if(!require("Hmisc")) install.packages("Hmisc"); library("Hmisc")
if(!require("fastDummies")) install.packages("fastDummies"); library("fastDummies")
if(!require("MASS")) install.packages("MASS"); library("MASS")
if(!require("pROC")) install.packages("pROC"); library("pROC")
if(!require("ROCR")) install.packages("pROC"); library("ROCR")
if(!require("klaR")) install.packages("klaR"); library("klaR")



setwd("~/OneDrive - IESEG/Semestre_2/Statistics and Machine Learning for MKT/Kaggle/data")

# Reading basetable
basetable<-fread('basetable_new_final.csv', header = T, sep = ',',stringsAsFactors = FALSE)
str(basetable)
dim(basetable)
table(basetable$woe_AppVersion)
topvars<-c("woe_AVProductStatesIdentifier"                        
,"woe_AvSigVersion"                                     
,"woe_Census_SystemVolumeTotalCapacity"                 
,"woe_SmartScreen"                                      
,"woe_Census_InternalPrimaryDiagonalDisplaySizeInInches"
,"woe_CountryIdentifier"                                
,"woe_AVProductsInstalled"                              
,"Census_IsVirtualDevice"                               
,"woe_OsBuildLab"                                       
,"woe_OsPlatformSubRelease"                             
,"Census_HasOpticalDiskDrive"                           
,"woe_Census_OSBuildRevision"                           
,"OsSuite"                                              
,"woe_AppVersion"                                       
,"woe_Census_MDC2FormFactor"                            
,"Census_IsSecureBootEnabled"                           
,"woe_LocaleEnglishNameIdentifier"                      
,"woe_Census_OSWUAutoUpdateOptionsName"                 
,"woe_Census_ActivationChannel"                         
,"AVProductsEnabled"                                    
,"woe_Census_ChassisTypeName"                           
,"woe_Census_OSEdition"                                 
,"woe_Census_FirmwareVersionIdentifier"                 
,"woe_Census_FirmwareManufacturerIdentifier"            
,"RtpStateBitfield"                                     
,"SMode"                                                
,"woe_Census_OSInstallTypeName"                         
,"woe_Census_FlightRing"                                
,"woe_Census_ProcessorCoreCount"                        
,"Census_ProcessorClass"                                
,"woe_Platform"                                         
,"woe_Census_PrimaryDiskTotalCapacity"                  
,"woe_Census_TotalPhysicalRAM"                          
,"woe_Census_OSArchitecture"                            
,"woe_Census_OSBuildNumber"
,"HasDetections")

# In data.table the "with" parameter indicates that topvars is not a column name, but a vector.
basetable2<-basetable[,topvars, with=FALSE]
dim(basetable)
dim(basetable2)
table(basetable2$woe_AVProductStatesIdentifier)
plot(table(basetable2$woe_AvSigVersion))
table(basetable2$HasDetections)

FacVar<-c("Census_IsVirtualDevice"
,"Census_HasOpticalDiskDrive"
,"OsSuite"
,"Census_IsSecureBootEnabled"
,"AVProductsEnabled"
,"RtpStateBitfield"
,"SMode"
,"Census_ProcessorClass"
,"HasDetections")

basetable2$Census_IsVirtualDevice<-as.factor(basetable2$Census_IsVirtualDevice)
basetable2$Census_HasOpticalDiskDrive<-as.factor(basetable2$Census_HasOpticalDiskDrive)
basetable2$OsSuite<-as.factor(basetable2$OsSuite)
basetable2$Census_IsSecureBootEnabled<-as.factor(basetable2$Census_IsSecureBootEnabled)
basetable2$AVProductsEnabled<-as.factor(basetable2$AVProductsEnabled)
basetable2$RtpStateBitfield<-as.factor(basetable2$RtpStateBitfield)
basetable2$SMode<-as.factor(basetable2$SMode)
basetable2$Census_ProcessorClass<-as.factor(basetable2$Census_ProcessorClass)

str(basetable2)

basetable2<-dummy_cols(basetable2, remove_first_dummy = TRUE)
basetable2<-basetable2[,-FacVar[-9],with=FALSE]
basetable2$HasDetections<-as.factor(basetable2$HasDetections)
levels(basetable2$HasDetections)<-c("F","T")

# Plot response variable, see that the data es proportional distributed
options(repr.plot.width=14, repr.plot.height=5)
plot(basetable2$HasDetections, main="HasDetections")

# Split train/test
train_index <- sample(1:nrow(basetable2), 0.7 * nrow(basetable2))

# Build X_train, y_train, X_test, y_test
train <- basetable2[train_index,]
test <- basetable2[-train_index,]

# Response balance 50%
plot(train$HasDetections)
plot(test$HasDetections)


# Train model0
fit_0<-lda(formula = HasDetections ~ ., 
           data = train, 
           prior = c(1,1)/2)

# Accuracy train0
pred0 = predict(fit_0, newdata = test)
train0_conf<-table(test$HasDetections,pred0$class)
train0_acc<-(train0_conf[1,1]+train0_conf[2,2])/sum(train0_conf)


pred0_ <- prediction(pred0$posterior[,2], test$HasDetections) 
perf0 <- performance(pred0_,"tpr","fpr")

# AUC train0
train0_auc_full<-performance(pred0_, "auc")
train0_auc<-unlist(slot(train0_auc_full , "y.values"))
train0_auc
#plot(perf0,colorize=TRUE)


# Prepare training scheme (trControl parameter)
# Repeated cross validation with 10 folds and 3 repeats
control <- trainControl(method="repeatedcv",
                        number=10,
                        repeats=3,
                        summaryFunction=twoClassSummary,
                        classProbs=TRUE,
                        savePredictions = TRUE)

# Linear Discriminant Analysis (LDA)
set.seed(7)
fit_lda <- train(HasDetections~., data=train, method="lda", metric="ROC",trControl=control)
# AUC train
train_auc<-as.numeric(fit_lda$results[2])
# Accuracy train
train_conf<-confusionMatrix(fit_lda)
train_acc<-(train_conf$table[1,1]+train_conf$table[2,2])/100

# Accuracy test
pred<-predict(fit_lda,newdata = test)
test_conf<-confusionMatrix(pred,test$HasDetections,positive = "T")
test_acc<-as.numeric(test_conf$overall[1])

# AUC test
probs<-predict(fit_lda,newdata = test,type="prob")
roc1<-roc(predictor=probs$T,
          response = test$HasDetections,
          levels = rev(levels(test$HasDetections)))
fit_lda$results$ROC
test_auc<-as.numeric(roc1$auc)

plot.roc(roc1,print.auc = TRUE, legacy.axes=TRUE,ylab = "TP (Sensitivity)",xlab = "FP (1-Specificity)")

# Training0
train0_acc
train0_auc

# Training
train_acc
train_auc

# Test
test_acc
test_auc

comparison<-cbind(c(train0_acc,train0_auc),c(train_acc,train_auc),c(test_acc,test_auc))
rownames(comparison)<-c("Accuracy","AUC")
colnames(comparison)<-c("Train0","Train","Test")
comparison

fit_lda$finalModel$scaling

sort(fit_lda$finalModel$scaling,decreasing=TRUE)

